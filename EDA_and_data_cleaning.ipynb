{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import itertools\n",
    "import helper_functions as helper\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.loads(line) for line in open('reviews_Electronics_5.json', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reviews to reduce class imabalance and reduce size of data\n",
    "remove_n_5 = 900000\n",
    "remove_n_4 = 247000\n",
    "remove_n_3 = 40000\n",
    "\n",
    "just5 = df.loc[df['overall'] == 5]\n",
    "just4 = df.loc[df['overall'] == 4]\n",
    "just3 = df.loc[df['overall'] == 3]\n",
    "\n",
    "# drop a random sample from each rating bucket\n",
    "drop_indices_5 = np.random.choice(just5.index, remove_n_5, replace=False)\n",
    "drop_indices_4 = np.random.choice(just4.index, remove_n_4, replace=False)\n",
    "drop_indices_3 = np.random.choice(just3.index, remove_n_3, replace=False)\n",
    "\n",
    "df_final = df.drop(drop_indices_5)\n",
    "df_final = df_final.drop(drop_indices_4)\n",
    "df_final = df_final.drop(drop_indices_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe for engineered features\n",
    "df_engineered = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of review\n",
    "df_engineered['review_length'] = df_final['reviewText'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for review\n",
    "df_engineered['word_count'] = df_final['reviewText'].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of exclamation points\n",
    "df_engineered['exclamation_count'] = df_final['reviewText'].apply(lambda x: x.count('!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of question marks\n",
    "df_engineered['question_count'] = df_final['reviewText'].apply(lambda x: x.count('?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include rating in this dataframe for visualization purposes\n",
    "df_engineered['overall'] = df_final['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered.to_csv('df_engineered.csv',index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    \"\"\"\n",
    "    clean_review(review):\n",
    "    Returns the text of a review without puncuation and capital letters\n",
    "    Params:\n",
    "        review: individual review from Amazon Product Review dataset\n",
    "    Returns:\n",
    "        a review with only lowercase letters and with puncuation removed\n",
    "    \"\"\"\n",
    "    clean = []\n",
    "    joined_clean_review = ''\n",
    "    # for each element in the review\n",
    "    for x in review:\n",
    "        # if the element is a punctuation, replace it with a space\n",
    "        if x in string.punctuation:\n",
    "            x = x.replace(x, \" \")\n",
    "        # otherwise turn the letter into its lowercase form    \n",
    "        elif x not in string.punctuation:\n",
    "            x = x.lower()\n",
    "        # append the letter to the empty list\n",
    "        clean.append(x)    \n",
    "        # join the letters into words\n",
    "        joined_clean_review = \"\".join(clean)\n",
    "\n",
    "    return joined_clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(clean_review):\n",
    "    \n",
    "    \"\"\" \n",
    "    get_tokens(clean_review):\n",
    "    Returns a list of the individual from a review\n",
    "    Params:\n",
    "        clean_review: a review that has been wiped of its puncuation and capital letters\n",
    "    Returns:\n",
    "        a list of words, excluding \"stop words\", that comprise a review\n",
    "    \"\"\"\n",
    "    \n",
    "    #  tokenize & remove stop words\n",
    "    list_of_tokens = [x for x in word_tokenize(clean_review) if x not in final_stopwords]\n",
    "    \n",
    "    # return list of text from each review\n",
    "    return list_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_words(list_of_tokens,lemmatizer):\n",
    "    \"\"\"\n",
    "    lem_words(list_of_tokens, lemmatizer):\n",
    "    Returns the lemmas of each token\n",
    "    Params:\n",
    "        list_of_tokens: list of words (tokens) from a single review\n",
    "        lemmatizer: instance of the NLTK lemmatizer class\n",
    "    Returns:\n",
    "        a string of lemmas that comprise a review\n",
    "    \"\"\"\n",
    "    wrd_list = [lemmatizer.lemmatize(word) for word in list_of_tokens]\n",
    "    # join the individual lemmas into a single string\n",
    "    return \" \".join(wrd_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand list of stopwords to include punctuatuion\n",
    "new_stopwords = [x.replace(\"'\",\"\") for x in stopwords.words('english')]\n",
    "final_stopwords = set(new_stopwords+stopwords.words('english')+list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make review text into a series\n",
    "reviews = df_final['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the cleaning, tokenizing, and lemmatizing of each review and save it to corpus\n",
    "corpus = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for review in tqdm(reviews):\n",
    "    clean = clean_review(review)\n",
    "    tokens = get_tokens(clean)\n",
    "    lemmas = lem_words(tokens,lemmatizer)\n",
    "    corpus.append(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the corpus into a dataframe\n",
    "df_corpus = pd.DataFrame(corpus, columns=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index \n",
    "df_corpus.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframes so we have the corpus + the ratings in one new dataframe\n",
    "df_reviews_final = pd.concat([df_final['overall'],df_corpus],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final dataframe to csv\n",
    "df_reviews_final.to_csv('final_df.csv',index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar graph that shows original distribution across rating buckets \n",
    "sns.set(style='white')\n",
    "ax=sns.countplot(x='overall', data=df)\n",
    "\n",
    "ax.set(xlabel='Rating', ylabel='Frequency')\n",
    "ax.set(title='Original Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_imbalance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar graph that shows new distribution across rating buckets after adjusting for class imbalance\n",
    "sns.set(style='white')\n",
    "ax=sns.countplot(x='overall', data=df_final)\n",
    "\n",
    "ax.set(xlabel='Rating', ylabel='Frequency')\n",
    "ax.set(title='Final Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_imbalance_fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create boxplot to visualize review length across rating buckets\n",
    "ax = sns.boxplot(x='overall',y='review_length',data=df_engineered, palette='Accent')\n",
    "ax.set(title='Length of reviews across ratings')\n",
    "ax.set(xlabel='Rating',ylabel='Number of words in review')\n",
    "plt.tight_layout()\n",
    "# plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boxplot to visualize number of exclamation points across rating buckets\n",
    "ax = sns.boxplot(x='overall',y='exclamation_count',data=df_engineered, palette='Accent')\n",
    "ax.set(title='Number of exclamation points used across ratings')\n",
    "ax.set(xlabel='Rating',ylabel='Number of exclamation points used')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
